---
order: 21
category: math
tag: 线性代数
star: false
sticky: false
excerpt: '线性代数-对角化和矩阵的幂'
---

# :boat:对角化和矩阵的幂
前面一节我们讨论了特征值和特征向量，这一节我们将讨论如何利用特征值和特征向量来简化矩阵的运算。

## 对角化矩阵 Diagonalizing a matrix 

如果矩阵A具有n个线性无关的特征向量，将它们作为列向量可以组成一个可逆方阵S，并且有：

![](/math/124.png =500x)

![](/math/125.png =1000x)

> 之前曾经提到过消元进行行操作和列操作最后会得到“相抵标准型”。现在我们得到的是矩阵的“相似标准形”,它还保有矩阵操作的基本性质——特征值，而相抵标准型只剩下最内核的秩信息还保留着。

## 矩阵的幂 Matrix powers of A

![](/math/126.png =1000x)

## 重特征值 Repeated eigenvalues

![](/math/127.png =1000x)

## 差分方程

![](/math/128.png =1000x)
> 特征向量线性无关 可以看成是uo所在空间的基 基的线性组合可以表示空间中的所有向量

![](/math/129.png =1000x)

![](/math/130.png =1000x)

![](/math/131.png =1000x)

> 很多人会问矩阵的特征值特征向量为什么这么神奇，可以把矩阵的操作变成一个简单的参数。还有人会问道为什么特征值在物理中出现非常频繁。对此我只能简单解释一下，物理中常见的被研究物体都有一个自身的内禀结构，这个内在结构的方向往往和观察者也就是外场的坐标有区别。当我们给物体施加一个外场刺激的时候，比如说外力或者电场极化等等，物体沿着其内在结构的取向来响应外场，但是观察者从外场坐标下采集反馈。实际上矩阵在不同坐标之间实现变换，特征向量显示了物体内结构的方向，特征值则是在这个主方向上物体对外场的响应参数。在有的领域直接将特征值称为伸缩系数，实际上它反应了在其所对应的特征向量方向上，内结构与外场之间的相互关系。
特征值还有一个应用是作为降维的判据，比如在图像压缩过程中，极小的特征值会被赋值为0，以此节省存储空间，也便于其它操作。反应在图像上，降维后的图像基本轮廓依旧清晰，图像细节有所牺牲。