---
order: 3
category: math
tag: 线性代数
star: false
sticky: false
excerpt: '线性代数-矩阵乘法和逆矩阵'
---

# :boat:矩阵乘法和逆矩阵

## 矩阵乘法

我们通过四种方法讨论如何使矩阵**A**与**B**相乘得到矩阵**C**。其中**A**为mXn（m行n列）矩阵，而**B**为nXp矩阵，则**C**为mXp矩阵，记C~ij~为矩阵C中第i行第j列的元素。

1. 标准方法

所谓标准方法就是我们在学习矩阵乘法时所学的方法，即C~ij~为A的第i行与B的第j列对应元素的乘积之和。
$$
c_{ij}=\sum_{k=1}^na_{ik}b_{kj}=a_{i1}b_{1j}+a_{i2}b_{2j}+\cdots+a_{in}b_{nj}
$$
例如

![](/math/16.png =700x)

$$
c_{34}=\sum_{k=1}^na_{3k}b_{k4}=a_{31}b_{14}+a_{32}b_{24}+\cdots+a_{3n}b_{n4}
$$

在学习线性代数时，我们都会奇怪，为什么矩阵运算这么奇怪，只有同型号的矩阵可以做加法，为什么不同型号的矩阵可以做乘法？

A.D.亚历山大洛夫编著的《数学：它的内容，方法和意义》第三卷中很好解释了这个问题。

我们先看看矩阵加法和数乘的规则

![](/math/17.png =700x)

本质上矩阵的代数运算就是线性方程组的运算

![](/math/18.webp =700x)

![](/math/19.webp =700x)

::: info
矩阵乘法符合结合律、分配率，但是不遵守交换律，这些通常通过定义加以证明，即将等号两侧矩阵的元素乘开，比较对应元素，从而得出相等或者不等的结论。我们也可以从变量替换的角度思考一下矩阵乘法运算定律。比如结合律，若方程组有如下关系$u=Ew$，$w=Dy$，$y=Ax$，则做变量替换可有$u=Ew=EDy=EDAx$。结合律为$(ED)A=E(DA)$，它表达的意思就是替换环节无论是先把u表示成$EDy$，再表示成$x$的表达式，又或者先把$w$表示成$DAx$，再把公式带入$u=Ew$都是等效的。分配率也一样，先做加法再进行变量替换，或者先做变量替换再相加也是等效的。但是交换律就不行了，若矩阵乘法满足交换律 那么$u=Ew=EDy=EDAx$就会$=EADx$,$D$的维度是$kxm$而$x$的维度是$mxn$，二者就不能组成线性方程组，当然也不能相乘。所以显然矩阵乘法不满足交换律

:::

2. 列操作

在前一节我们知道，矩阵乘以一列等于一列，那么$C=AB$中矩阵$C$的列向量是矩阵$A$列向量的线性组合，组合的“权”就是矩阵$B$第n列的各个分量。

也就是说，$C$中第一列就是$A$中每列的线性组合，`权重`就是$B$中的第一列，以此类推。
$$
AB = A\begin{bmatrix} b_1&b_2&\cdots&b_p \end{bmatrix} = \begin{bmatrix} Ab_1&Ab_2&\cdots&Ab_i \end{bmatrix}
$$
其中$bi$,$Abi$为列向量

![](/math/20.webp =700x)

3. 行操作

同理，$C=AB$中矩阵$C$的行向量是矩阵$B$行向量的线性组合，组合的“权”就是矩阵$A$第m行的各个分量。

$$
AB = \begin{bmatrix} a_1\\a_2\\\vdots\\a_m \end{bmatrix}B = \begin{bmatrix} a_1B\\a_2B\\\vdots\\a_mB \end{bmatrix}
$$
其中$ai$,$aiB$为行向量

![](/math/21.jpg =700x)

4. 列乘以行

矩阵$A$的第$k$列是一个$m1$的向量，而矩阵$B$第$k$行是一个$1p$的向量，两向量相乘会得到一个矩阵$Ck$，将所有的$n$个矩阵相加记得到$C$。


$$
AB = \sum_{k=1}^n\begin{bmatrix} a_{1k} \\ \vdots \\ a_{mk} \end{bmatrix} \begin{bmatrix} b_{k1} & \cdots & a_{kp} \end{bmatrix} \quad
$$

举例
$$
\begin{bmatrix} 2&7 \\ 3&8 \\ 4&9 \end{bmatrix}\begin{bmatrix} 1&6 \\ 0&0 \end{bmatrix}= \begin{bmatrix} 2 \\ 3 \\ 4 \end{bmatrix}\begin{bmatrix} 1&6 \end{bmatrix}+\begin{bmatrix} 7 \\ 8 \\ 9 \end{bmatrix}\begin{bmatrix} 0&0 \end{bmatrix} = \begin{bmatrix} 2&12 \\ 3&18 \\ 4&24 \end{bmatrix}
$$

## 分块乘法block multiplication

如果将矩阵`A`和矩阵`B`划分为严格匹配的区块，则矩阵乘法可以通过分块的乘法加以实现。

$$
\begin{bmatrix} A_{11}&A_{12} \\ A_{21}&A_{22} \end{bmatrix}\begin{bmatrix} B_{11}&B_{12} \\ B_{21}&B_{22} \end{bmatrix} = \begin{bmatrix} A_{11}B_{11}+A_{12}B_{21}&A_{11}B_{12}+A_{12}B_{22} \\ A_{21}B_{11}+A_{22}B_{21}&A_{21}B_{12}+A_{22}B_{22} \end{bmatrix}
$$
计算方法与标准算法中矩阵里元素的操作方式相同。

我们看下面这张图，很清晰的看出结果是怎么来的

![](/math/18.png =350x)

我们把其分块拆开，利用前面的标准方法，可以看到C1就是经过C1=A1B1+A2B3的运算计算出来的，A1中的元素只和B1的元素进行运算，A2只和B3进行运算，C1为两者加和。

![](/math/22.webp =350x)

## 逆矩阵 Inverse

如果矩阵A是方阵，若存在逆矩阵$A^{-1}$，使得$AA^{-1}=A^{-1}A=I$ （左逆矩阵等于右逆矩阵），则称矩阵A可逆（invertible）或者矩阵A非奇异（nonsingular），$A^{-1}$为A的逆矩阵。

反之，如果A为奇异（singular），则其没有逆矩阵。它的行列式为0。

我们先来看看矩阵不可逆的例子。

$$
A = \begin{bmatrix} 1&2 \\ 3&6 \end{bmatrix}
$$
A为什么不可逆呢。我们用两种角度去理解一下
- 根据它的定义，如果A可逆，那么$AA^{-1}=I$，也就是$\begin{bmatrix} 1&2 \\ 3&6 \end{bmatrix}\begin{bmatrix} a&b \\ c&d \end{bmatrix}=\begin{bmatrix} 1&0 \\ 0&1 \end{bmatrix}$。我们只看结果C的第一列，它等于$\begin{bmatrix} 1&2 \\ 3&6 \end{bmatrix}\begin{bmatrix} a \\ c \end{bmatrix}=\begin{bmatrix} 1 \\ 0 \end{bmatrix}$。怎样的a和c会使得其成立，换一个说法，A的线性组合会得到$\begin{bmatrix} 1 \\ 0 \end{bmatrix}$吗  显然是不会的，因为A的第一列和第二列的处于同一条直线，无论怎么组合都不会得到$\begin{bmatrix} 1 \\ 0 \end{bmatrix}$。所以A不可逆。
- 若A为不可逆矩阵(奇异矩阵)，则方程`Ax=0`存在非零解`x`，注意一定是非零解，无论是否可逆，0解一定存在。例如$\begin{bmatrix} 1&2 \\ 3&6 \end{bmatrix}\begin{bmatrix} 2 \\ -1 \end{bmatrix}=\begin{bmatrix} 0 \\ 0 \end{bmatrix}$.也就是说，只要我们找到一个非零向量`x`使得`Ax=0`，那么A就是不可逆的。为什么呢。在第一节我们知道，矩阵A乘一个向量x得到一个向量c，这个向量c是矩阵A列向量的线性组合，若这个矩阵是n维的，且线性无关，那么这n维向量的线性组合可以表示整个n维空间，若想得到0向量，x只能为0,由于可以表示整个n维空间，单位矩阵的某一列当然不在话下。反之，若有n维中有两个向量线性相关，也就是方向相同。那么想得到0向量，x可以为非零向量，只需要让这两个线性相关的向量组合为0，其余向量权值为0即可，同样的，若想得到单位矩阵的某一列，显然是不可以的，因为这两个向量的方向相同，无法组合出单位矩阵的某一列。所以A不可逆。也就是说，不可逆矩阵的某些列向量线性组合可以得到0

我们只需要找到一个非零向量x，使得`Ax=0`，即可说明A是不可逆的。换而言之，若矩阵A存在逆矩阵，则方程Ax=0只有零解。证明：反设其存在非零解x，则有$x=(AA^{-1})x=A(A^{-1}x)=0$，与假设矛盾，所以不存在非零解。

逆矩阵重要的当然是求出它的逆矩阵，我们已经可以判断一个矩阵是不是逆矩阵了，那么对于一个可逆矩阵，怎么怎么求它的逆矩阵呢。

![](/math/23.png =300x)

我们先看一部分$\begin{bmatrix} 1&3 \\ 2&7 \end{bmatrix}\begin{bmatrix} a \\ c \end{bmatrix}=\begin{bmatrix} 1 \\ 0 \end{bmatrix}$,这是不是和前面的解方程组的矩阵形式是一样的，我们可以用同样的方法解出a和c的值，然后再解$\begin{bmatrix} 1&3 \\ 2&7 \end{bmatrix}\begin{bmatrix} b \\ d \end{bmatrix}=\begin{bmatrix} 0 \\ 1 \end{bmatrix}$，这样就可以得到逆矩阵了。但是若尔当对高斯说，A是一样的，但是b和d不一样，那么我们就要重复计算一遍，这样就很麻烦了。所以我们要找到一种方法，可以一次性解出所有的值。这就是高斯-若尔当消元法
### 高斯-若尔当消元法 Gauss-Jordan Elimination
按照这种方法，我们可以同时处理上面两个方程.
- 将结果向量放到一起，形成增广矩阵，这个矩阵是将两个结果向量都放在一起。

![](/math/24.png =200x)
- 按照高斯消元进行消元得到上三角矩阵,如果按照高斯的方法，接下来就是回代了，解出我们需要的值

![](/math/25.png =200x)

- 按照若尔当的做法继续消元，用第一行减去第二行的若干倍，最后原矩阵变为单位阵，这时右侧的矩阵即为逆矩阵。

![](/math/26.png =200x)

这十分好理解，下面的01就是a\*0+b\*1=-2 c\*0+d\*1=1,上面的10就是a\*1+b\*0=7 c\*1+d\*0=-3

这是我们的理解，怎么证明它就是逆矩阵呢。对`A`进行一系列消元操作，相当于左乘消元矩阵`E`，此时消元的结果为`EA=I`，因为右侧矩阵也进行了同样消元操作，也等于左乘矩阵`E`，则右侧矩阵为`EI=E`。由`EA=I` 可知这里的`E`就是`A`的逆矩阵，因此右侧矩阵给出的就是逆矩阵$E=A^{-1}$ 

![](/math/27.png =350x)